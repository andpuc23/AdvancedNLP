{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from extract_features import extract_features, split_gold_column\n",
    "from read_conllu_to_csv import read_conllu_write_csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../UP-1.0/input/en_ewt-up-train-small.conllu\"\n",
    "dev_file = \"../UP-1.0/input/en_ewt-up-dev.conllu\"\n",
    "test_file = \"../UP-1.0/input/en_ewt-up-test.conllu\"\n",
    "\n",
    "out_train_file = '../UP-1.0/output/read_conllu_train-small.csv'\n",
    "out_test_file = '../UP-1.0/output/read_conllu_test.csv'\n",
    "out_dev_file = '../UP-1.0/output/read_conllu_dev.csv'\n",
    "\n",
    "feat_train_file = '../UP-1.0/features/extract_features_out_train-small.csv'\n",
    "feat_test_file = '../UP-1.0/features/extract_features_out_test.csv'\n",
    "feat_dev_file = '../UP-1.0/features/extract_features_out_dev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read_conllu_dev.csv produced!\n",
      "File read_conllu_test.csv produced!\n",
      "File read_conllu_train-small.csv produced!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al</td>\n",
       "      <td>Al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>1</td>\n",
       "      <td>flat</td>\n",
       "      <td>1:flat</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>6:amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143887</th>\n",
       "      <td>20</td>\n",
       "      <td>miseries</td>\n",
       "      <td>misery</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "      <td>11</td>\n",
       "      <td>obl</td>\n",
       "      <td>11:obl:for</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ARG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143888</th>\n",
       "      <td>21</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>23</td>\n",
       "      <td>case</td>\n",
       "      <td>23:case</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143889</th>\n",
       "      <td>22</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>23</td>\n",
       "      <td>det</td>\n",
       "      <td>23:det</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890</th>\n",
       "      <td>23</td>\n",
       "      <td>region</td>\n",
       "      <td>region</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>20</td>\n",
       "      <td>nmod</td>\n",
       "      <td>20:nmod:of</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143891</th>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>5:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143892 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2      3     4                          5   6   \\\n",
       "0        1        Al        Al  PROPN   NNP                Number=Sing   0   \n",
       "1        2         -         -  PUNCT  HYPH                          _   1   \n",
       "2        3     Zaman     Zaman  PROPN   NNP                Number=Sing   1   \n",
       "3        4         :         :  PUNCT     :                          _   1   \n",
       "4        5  American  american    ADJ    JJ                 Degree=Pos   6   \n",
       "...     ..       ...       ...    ...   ...                        ...  ..   \n",
       "143887  20  miseries    misery   NOUN   NNS                Number=Plur  11   \n",
       "143888  21        of        of    ADP    IN                          _  23   \n",
       "143889  22       the       the    DET    DT  Definite=Def|PronType=Art  23   \n",
       "143890  23    region    region   NOUN    NN                Number=Sing  20   \n",
       "143891  24         .         .  PUNCT     .                          _   5   \n",
       "\n",
       "           7           8              9  10    11  \n",
       "0        root      0:root  SpaceAfter=No  _     _  \n",
       "1       punct     1:punct  SpaceAfter=No  _     _  \n",
       "2        flat      1:flat              _  _     _  \n",
       "3       punct     1:punct              _  _     _  \n",
       "4        amod      6:amod              _  _     _  \n",
       "...       ...         ...            ... ..   ...  \n",
       "143887    obl  11:obl:for              _  _  ARG2  \n",
       "143888   case     23:case              _  _     _  \n",
       "143889    det      23:det              _  _     _  \n",
       "143890   nmod  20:nmod:of  SpaceAfter=No  _     _  \n",
       "143891  punct     5:punct              _  _     _  \n",
       "\n",
       "[143892 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_conllu_write_csv(dev_file, out_dev_file)\n",
    "read_conllu_write_csv(test_file, out_test_file)\n",
    "read_conllu_write_csv(train_file, out_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features(out_dev_file, feat_dev_file)\n",
    "extract_features(out_train_file, feat_train_file)\n",
    "extract_features(out_test_file, feat_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_id = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indetification_labels(df):\n",
    "    # df = pd.read_csv( '../UP-1.0/features/extract_features_out_dev.csv', sep='\\t')\n",
    "    preds, args = split_gold_column(df.Label.tolist())\n",
    "    ident_args = [1 if a != '_' else 0 for a in args]\n",
    "    df['Identify args'] = ident_args\n",
    "    df['Preds'] = preds\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Token    PoS     Lemma Dependency    Head Head_POS  \\\n",
      "1        Al  PROPN        Al   compound   Zaman    PROPN   \n",
      "2         -  PUNCT         -      punct   Zaman    PROPN   \n",
      "3     Zaman  PROPN     Zaman       ROOT   Zaman    PROPN   \n",
      "4         :  PUNCT         :      punct  killed     VERB   \n",
      "5  American    ADJ  american       amod  forces     NOUN   \n",
      "\n",
      "  Morphological Feature                                    Word Embeddings  \\\n",
      "1           Number=Sing  tensor([-0.7131, -0.9817,  1.2258,  0.0932, -0...   \n",
      "2        PunctType=Dash  tensor([-0.9273, -1.1841,  4.7078, -0.0548,  1...   \n",
      "3           Number=Sing  tensor([-0.5911, -1.4489, -0.7058,  0.7999,  0...   \n",
      "4                     _  tensor([ 0.4395,  0.0779,  0.9455, -0.2140,  0...   \n",
      "5            Degree=Pos  tensor([-0.8749, -0.9839, -0.6887,  1.8970, -0...   \n",
      "\n",
      "  Named Entities                Path to head texts         Path to head POS  \\\n",
      "1         PERSON                            ['Al']                ['PROPN']   \n",
      "2         PERSON                             ['-']                ['PUNCT']   \n",
      "3         PERSON                                []                       []   \n",
      "4              _                   [':', 'killed']        ['PUNCT', 'VERB']   \n",
      "5           NORP  ['American', 'forces', 'killed']  ['ADJ', 'NOUN', 'VERB']   \n",
      "\n",
      "                   Context                   POS Context  Identify args Preds  \n",
      "1          [[None, Al, -]]          [[None, 'PROPN', -]]              0     _  \n",
      "2         [[Al, -, Zaman]]        [[Al, 'PUNCT', Zaman]]              0     _  \n",
      "3          [[-, Zaman, :]]             [[-, 'PROPN', :]]              0     _  \n",
      "4   [[Zaman, :, American]]  [[Zaman, 'PUNCT', American]]              0     _  \n",
      "5  [[:, American, forces]]          [[:, 'ADJ', forces]]              0     _  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Token                    0\n",
       "PoS                      0\n",
       "Lemma                    0\n",
       "Dependency               0\n",
       "Head                     0\n",
       "Head_POS                 0\n",
       "Morphological Feature    0\n",
       "Word Embeddings          0\n",
       "Named Entities           0\n",
       "Path to head texts       0\n",
       "Path to head POS         0\n",
       "Context                  0\n",
       "POS Context              0\n",
       "Identify args            0\n",
       "Preds                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(feat_train_file, sep='\\t')\n",
    "df_dev = pd.read_csv(feat_dev_file, sep='\\t')\n",
    "df_test = pd.read_csv(feat_test_file, sep='\\t')\n",
    "\n",
    "df_train = add_indetification_labels(df_train)\n",
    "df_dev = add_indetification_labels(df_dev)\n",
    "df_test = add_indetification_labels(df_test)\n",
    "\n",
    "# this is used to remove the first line of each dataframe, since it takes the first line (,0,1,2,3,4,5,6,7,8,9,10,11)\n",
    "# of the output of read_conllu_to_csv. \n",
    "df_train = df_train.iloc[1:]\n",
    "df_dev = df_dev.iloc[1:]\n",
    "df_test = df_test.iloc[1:]\n",
    "\n",
    "# only the rows where token is not NaN.  \n",
    "df_train = df_train[df_train['Token'].notna()]\n",
    "df_dev = df_dev[df_dev['Token'].notna()]\n",
    "df_test = df_test[df_test['Token'].notna()]\n",
    "\n",
    "# in the label-column, only missing values are now labeled as None_placeholder.  \n",
    "df_train.Label = df_train['Label'].fillna(value='None_placeholder')\n",
    "df_dev.Label = df_dev['Label'].fillna(value='None_placeholder')\n",
    "df_test.Label = df_test['Label'].fillna(value='None_placeholder')\n",
    "\n",
    "#in the head columns, missing values in Head are now labeled as '_'. \n",
    "df_train.Head = df_train.Head.fillna(value='_')\n",
    "df_dev.Head = df_dev.Head.fillna(value='_')\n",
    "df_test.Head = df_test.Head.fillna(value='_')\n",
    "#print(df_train.head())\n",
    "\n",
    "# this drops the GOLD-columns in each file\n",
    "df_train.drop(columns=['Gold'], inplace=True)\n",
    "df_dev.drop(columns=['Gold'], inplace=True)\n",
    "df_test.drop(columns=['Gold'], inplace=True)\n",
    "\n",
    "df_train.drop(columns=['Label'], inplace=True)\n",
    "df_dev.drop(columns=['Label'], inplace=True)\n",
    "df_test.drop(columns=['Label'], inplace=True)\n",
    "\n",
    "#in the Morphological Feature column, missing values are now labeled as '_'. \n",
    "df_train['Morphological Feature'] = df_train['Morphological Feature'].fillna(value='_')\n",
    "df_dev['Morphological Feature'] = df_dev['Morphological Feature'].fillna(value='_')\n",
    "df_test['Morphological Feature'] = df_test['Morphological Feature'].fillna(value='_')\n",
    "\n",
    "df_train.to_csv('training.csv', sep='\\t', index=False)\n",
    "print(df_train.head())\n",
    "#this checks if there are any nan-values left.\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Identify args', axis='columns')\n",
    "X_dev = df_dev.drop('Identify args', axis='columns')\n",
    "X_test = df_test.drop('Identify args', axis='columns')\n",
    "\n",
    "y_train_id = df_train['Identify args']\n",
    "y_test_id = df_test['Identify args']\n",
    "y_dev_id = df_dev['Identify args']\n",
    "\n",
    "X_train_vec = vectorizer_id.fit_transform(X_train.to_dict('records'))\n",
    "X_dev_vec = vectorizer_id.transform(X_dev.to_dict('records'))\n",
    "X_test_vec = vectorizer_id.transform(X_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "model_id.fit(X_train_vec, y_train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_id = model_id.predict(X_test_vec)\n",
    "#this one is executed to eventually save the predictions as a feature for classification\n",
    "y_train_pred_id = model_id.predict(X_train_vec)\n",
    "\n",
    "df_test_pred = pd.DataFrame(y_pred_id, columns=['Predicted'])\n",
    "df_test_pred = pd.concat([df_test, df_test_pred], axis=1)\n",
    "\n",
    "\n",
    "#this is dropped to make the output more readable\n",
    "df_test_pred.drop(columns=['Word Embeddings'], inplace=True)\n",
    "df_test_pred.to_csv('../UP-1.0/predictions/identification_test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS FOR ARG IDENTIFICATION\n",
      "precision\t0.6473609012186728\n",
      "recall\t0.5554077674006237\n",
      "f1\t0.57201181977585\n"
     ]
    }
   ],
   "source": [
    "print(\"METRICS FOR ARG IDENTIFICATION\")\n",
    "print('precision', precision_score(y_test_id, y_pred_id, average='macro'), sep='\\t')\n",
    "print('recall', recall_score(y_test_id, y_pred_id, average='macro'), sep='\\t')\n",
    "print('f1', f1_score(y_test_id, y_pred_id, average='macro'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     92983\n",
      "           1       0.37      0.13      0.20      9124\n",
      "\n",
      "    accuracy                           0.90    102107\n",
      "   macro avg       0.65      0.56      0.57    102107\n",
      "weighted avg       0.87      0.90      0.88    102107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_id, y_pred_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token                    0\n",
       "PoS                      0\n",
       "Lemma                    0\n",
       "Dependency               0\n",
       "Head                     0\n",
       "Head_POS                 0\n",
       "Morphological Feature    0\n",
       "Named Entities           0\n",
       "Path to head texts       0\n",
       "Path to head POS         0\n",
       "Context                  0\n",
       "POS Context              0\n",
       "Label                    0\n",
       "Predicted                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(feat_train_file, sep='\\t')\n",
    "df_dev = pd.read_csv(feat_dev_file, sep='\\t')\n",
    "df_test = pd.read_csv(feat_test_file, sep='\\t')\n",
    "\n",
    "#thi is from the identification, it is now made a feature \n",
    "#df_test_pred = pd.DataFrame(y_pred_id, columns=['Classification'])\n",
    "#y_train_pred_id = model_id.predict(X_train_vec)\n",
    "#df_train['Predicted Preds'] = y_train_pred_id\n",
    "\n",
    "df_train = df_train.iloc[1:]\n",
    "df_dev = df_dev.iloc[1:]\n",
    "df_test = df_test.iloc[1:]\n",
    "\n",
    "#the output of the identification model is here given as an input feature for the classification model\n",
    "df_train['Predicted'] = y_train_pred_id\n",
    "df_test['Predicted'] = y_pred_id\n",
    "\n",
    "df_train = df_train.drop('Gold', axis='columns')\n",
    "df_test = df_test.drop('Gold', axis='columns')\n",
    "df_dev = df_dev.drop('Gold', axis='columns')\n",
    "\n",
    "df_train['Label'] = df_train['Label'].replace('V', '_')\n",
    "df_test['Label'] = df_test['Label'].replace('V', '_')\n",
    "df_dev['Label'] = df_dev['Label'].replace('V', '_')\n",
    "\n",
    "df_train['Morphological Feature'] = df_train['Morphological Feature'].fillna(value='_')\n",
    "df_dev['Morphological Feature'] = df_dev['Morphological Feature'].fillna(value='_')\n",
    "df_test['Morphological Feature'] = df_test['Morphological Feature'].fillna(value='_')\n",
    "\n",
    "y_train = df_train['Label']\n",
    "y_test = df_test['Label']\n",
    "y_dev = df_dev['Label']\n",
    "\n",
    "X_train = df_train.drop('Label', axis='columns')\n",
    "X_dev = df_dev.drop('Label', axis='columns')\n",
    "X_test = df_test.drop('Label', axis='columns')\n",
    "\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = vectorizer.fit_transform(X_train.to_dict('records'))\n",
    "X_dev_vec = vectorizer.transform(X_dev.to_dict('records'))\n",
    "X_test_vec = vectorizer.transform(X_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "#this is only dropped to make the file more readable\n",
    "df_test_pred = pd.DataFrame(y_pred, columns=['Pred_Classification'])\n",
    "df_test_pred = pd.concat([df_test, df_test_pred], axis=1)\n",
    "\n",
    "\n",
    "#this is dropped to make the output more readable\n",
    "df_test_pred.drop(columns=['Word Embeddings'], inplace=True)\n",
    "df_test_pred.to_csv('../UP-1.0/predictions/classification_test.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS FOR ARG CLASSIFICATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\t0.17556101275703556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall\t0.10675632935777514\n",
      "f1\t0.11298906665207491\n"
     ]
    }
   ],
   "source": [
    "print(\"METRICS FOR ARG CLASSIFICATION\")\n",
    "print('precision', precision_score(y_test, y_pred, average='macro'), sep='\\t')\n",
    "print('recall', recall_score(y_test, y_pred, average='macro'), sep='\\t')\n",
    "print('f1', f1_score(y_test, y_pred, average='macro'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          11       0.00      0.00      0.00        39\n",
      "        ARG0       0.10      0.14      0.12       787\n",
      "        ARG1       0.07      0.02      0.03      2735\n",
      "    ARG1-DSP       0.00      0.00      0.00         0\n",
      "        ARG2       0.40      0.23      0.29      1385\n",
      "        ARG3       0.00      0.00      0.00        60\n",
      "        ARG4       0.00      0.00      0.00        86\n",
      "    ARGM-ADJ       0.00      0.00      0.00       223\n",
      "    ARGM-ADV       0.13      0.01      0.02      1925\n",
      "    ARGM-CAU       0.00      0.00      0.00        11\n",
      "    ARGM-DIR       0.00      0.00      0.00         3\n",
      "    ARGM-DIS       0.39      0.28      0.33       279\n",
      "    ARGM-EXT       0.00      0.00      0.00        49\n",
      "    ARGM-GOL       1.00      1.00      1.00        82\n",
      "    ARGM-LOC       0.00      0.00      0.00       183\n",
      "    ARGM-LVB       0.00      0.00      0.00         0\n",
      "    ARGM-MNR       0.00      0.00      0.00        44\n",
      "    ARGM-MOD       1.00      0.02      0.03       619\n",
      "    ARGM-NEG       0.00      0.00      0.00        74\n",
      "    ARGM-PRD       0.00      0.00      0.00        21\n",
      "    ARGM-PRP       0.00      0.00      0.00        44\n",
      "    ARGM-PRR       0.00      0.00      0.00        40\n",
      "    ARGM-TMP       0.56      0.10      0.17       398\n",
      "      C-ARG1       0.00      0.00      0.00        35\n",
      "  C-ARG1-DSP       0.00      0.00      0.00         2\n",
      "           _       0.92      0.98      0.95     92983\n",
      "\n",
      "    accuracy                           0.90    102107\n",
      "   macro avg       0.18      0.11      0.11    102107\n",
      "weighted avg       0.86      0.90      0.87    102107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sezentuvay/opt/anaconda3/envs/myenvironment/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "21634ba1c762bc3505d86a0c5bab9f12f9ed8aa21c75b1f37c314fb51f344c98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
