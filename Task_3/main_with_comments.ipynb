{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Role Labelling(SRL) with BERT \n",
    "##### by Andrei, Sezen and Emma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRL is the task of identifying and classifying predicate-argument semantic roles within a text and eventually answer the questions of: who, did what to whom, and where, when...etc. It comprises four main\n",
    "sub-tasks: predicate detection, predicate sense disambiguation, argument identification, argument classification. \n",
    "In this notebook, we will focus solely on argument identification and classification. \n",
    "\n",
    "To carry out the task, we will use the English-language Universal Proposition Banks dataset. The dataset is structured as a CoNLL-U file containing different sentences. In the file, each sentence is first represented with a document and sentence id and then as raw text. \n",
    "Then, each sentence is broken down in tokens with each line concerning a single token and its corresponding syntactic features. The various fields are separated by tabs. If a sentence contains predicates, then the next field indicates the labeled (disambiguated) predicates within each sentence, while the final field marks their corresponding arguments.\n",
    "\n",
    "The disambiguated predicates in the gold data will be used as the basis for the argument extraction and classification while the process will be performed in a single step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.0.3 (from -r requirements.txt (line 1))\n",
      "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting spacy==3.7.4 (from -r requirements.txt (line 2))\n",
      "  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting scikit-learn==1.3.0 (from -r requirements.txt (line 3))\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting transformers>=4.11.0 (from -r requirements.txt (line 4))\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets (from -r requirements.txt (line 5))\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting seqeval (from -r requirements.txt (line 6))\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 7))\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.0.3->-r requirements.txt (line 1))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.4->-r requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.4->-r requirements.txt (line 2)) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.4->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.4->-r requirements.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.4->-r requirements.txt (line 2)) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn==1.3.0->-r requirements.txt (line 3))\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn==1.3.0->-r requirements.txt (line 3))\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.3.0->-r requirements.txt (line 3))\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.11.0->-r requirements.txt (line 4)) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers>=4.11.0->-r requirements.txt (line 4))\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.11.0->-r requirements.txt (line 4)) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.11.0->-r requirements.txt (line 4))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers>=4.11.0->-r requirements.txt (line 4))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.11.0->-r requirements.txt (line 4))\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (2023.12.2)\n",
      "Collecting aiohttp (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 7)) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 7)) (2.2.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 5))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 5))\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 5))\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 5))\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->-r requirements.txt (line 5))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.11.0->-r requirements.txt (line 4)) (4.9.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4->-r requirements.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4->-r requirements.txt (line 2)) (2023.11.17)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 7)) (3.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.4->-r requirements.txt (line 2)) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy==3.7.4->-r requirements.txt (line 2))\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy==3.7.4->-r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 7)) (1.3.0)\n",
      "Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.3/922.3 kB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=af48b4777ccd242f6a4f54f3210964c01209e113a87d60f1fdd0d026a93ca7cd\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built seqeval\n",
      "Installing collected packages: cymem, xxhash, wasabi, tzdata, typer, threadpoolctl, spacy-loggers, spacy-legacy, smart-open, scipy, safetensors, regex, pydantic-core, pyarrow-hotfix, pyarrow, murmurhash, multidict, langcodes, joblib, frozenlist, dill, cloudpathlib, catalogue, blis, async-timeout, annotated-types, yarl, srsly, scikit-learn, pydantic, preshed, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, seqeval, confection, aiohttp, accelerate, weasel, transformers, thinc, spacy, datasets\n",
      "Successfully installed accelerate-0.28.0 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 huggingface-hub-0.21.4 joblib-1.3.2 langcodes-3.3.0 multidict-6.0.5 multiprocess-0.70.16 murmurhash-1.0.10 pandas-2.0.3 preshed-3.0.9 pyarrow-15.0.2 pyarrow-hotfix-0.6 pydantic-2.6.4 pydantic-core-2.16.3 regex-2023.12.25 safetensors-0.4.2 scikit-learn-1.3.0 scipy-1.12.0 seqeval-1.2.2 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 threadpoolctl-3.4.0 tokenizers-0.15.2 transformers-4.38.2 typer-0.9.0 tzdata-2024.1 wasabi-1.1.2 weasel-0.3.4 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from code_.process_conll import process_file, advanced_process_file\n",
    "from code_.evaluation import class_report_base, class_report_advanced, shrink_predictions\n",
    "from code_.bert import Tokenizer, convert_to_dataset, compute_metrics, get_labels_list_from_dataset, task, batch_size, model_checkpoint\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Approach\n",
    "The argument identification and classification experiment will be carried out with two different approaches both employing the BERT model. \n",
    "\n",
    "Given that the predicate identification is a given in this experiment, the main challenge of this task is to find a solution for\n",
    "representing the relation between each sentence and the predicate under consideration.\n",
    "\n",
    "In the original PropBank dataset, sentences can host any number of predicates (including none) thus, when a sentence has two or more predicates, the rest of its tokens are bound to express different arguments in relation to each predicate. Consequently, in order for the model to be able to correctly predict and assign argument labels for a sentence, we need to first establish - each time - the predicate under consideration. For example, in the sentence:\n",
    "\n",
    "\"John cooked dinner and served dessert to his guests.\"\n",
    "\n",
    "for both predicates \"cooked\" and \"served\", the subject (ARG0) is \"John\", but the object (ARG1) is \"dinner\" for \"cooked\" and \"dessert\" for \"served\".\n",
    "\n",
    "Thus, our focus lies in determining an effective representation for the model input allowing for the model to classify the arguments within a sentence relative to a specific predicate. The first step is reduplicating each sentence based on the number of its predicates so each sentence is presented in the dataset each time in relation to a unique predicate.\n",
    "\n",
    "Next, the process involves structuring the input data in a manner that enables the model to understand the relationships between tokens and the possible argument labels within the context of a specific predicate.\n",
    "\n",
    "To experiment on the basis of the input representation, we will build both a baseline and an advanced model. In both cases the relation of each sentence and a specific predicate will be encoded into the model's input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model(s) & Loading the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Baseline\n",
    "\n",
    "The function of the baseline model is to offer a straightforward approach to the task, serving as a reference point for evaluating the effectiveness of the more advanced model. As such, the baseline will be employing a more simplistic approach to input representation inspired by Shi and Lin (2019):\n",
    "\n",
    "[CLS] Barack Obama went to Paris [SEP] went [SEP] ,\n",
    "\n",
    "in which the predicate information - each time signaling the predicate in question - only consists of the predicate token itself. At the same time, the [CLS] token typically represents the aggregate understanding of the entire sentence, serving as a sentence-level representation and capturing the contextual information necessary for semantic role labeling.\n",
    "The [SEP] token demarcates the boundaries between different segments of the input. In this representation, it separates the sentence from the predicate.\n",
    "\n",
    "This approach entails limitations. The mosts obvious one would be the case in which a sentence contains the same predicate twice. In this case only using the predicate itself as the predicate indicator would not allow the model to distinguish between the two different predicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_file(): dataframe len: 4979\n",
      "process_file(): dataframe len: 40498\n",
      "process_file(): dataframe len: 4802\n"
     ]
    }
   ],
   "source": [
    "df_val = process_file('data/raw/en_ewt-up-dev.conllu')\n",
    "df_train = process_file('data/raw/en_ewt-up-train.conllu')\n",
    "df_test = process_file('data/raw/en_ewt-up-test.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline model, the datasets are transformed into dataframes using the imported `process_file` fuction. The function splits the text into individual sentences based on empty lines (\\n\\n) with each line in the produced dataframe concerning a single sentence. The function then retrieves predicate indices and columns from the current sentence and extract labels for tokens in relation to predicates from the current sentence. Finally, it retrieves the corresponding word for each predicate from the sentence and adds a row to the DataFrame.\n",
    "\n",
    "More specifically, the first column of the DataFrame hosts the tokenized sentence. The second column hosts one predicate per sentence each time. The third column gives the length of the argument columns attached to each predicate while the last one hosts the labelled arguments for each predicate mapped to the sentence tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicate</th>\n",
       "      <th>pred columns</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[What, if, Google, Morphed, Into, GoogleOS, ?]</td>\n",
       "      <td>Morphed</td>\n",
       "      <td>11</td>\n",
       "      <td>_, _, ARG1, V, _, ARG2, _</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[What, if, Google, expanded, on, its, search, ...</td>\n",
       "      <td>expanded</td>\n",
       "      <td>11</td>\n",
       "      <td>_, _, ARG0, V, _, _, _, _, _, _, _, _, _, _, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>way</td>\n",
       "      <td>11</td>\n",
       "      <td>_, _, _, _, _, V, _, _, _, _, _, _, _, _, _, _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>is</td>\n",
       "      <td>12</td>\n",
       "      <td>_, _, _, _, _, ARGM-DIS, _, V, ARG1, _, _, _, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[This, BuzzMachine, post, argues, that, Google...</td>\n",
       "      <td>post</td>\n",
       "      <td>11</td>\n",
       "      <td>_, ARG2, V, _, _, _, _, _, _, _, _, _, _, _, _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[This, BuzzMachine, post, argues, that, Google...</td>\n",
       "      <td>argues</td>\n",
       "      <td>12</td>\n",
       "      <td>_, _, ARG0, V, _, _, _, _, _, _, _, ARG1, _, _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[This, BuzzMachine, post, argues, that, Google...</td>\n",
       "      <td>rush</td>\n",
       "      <td>13</td>\n",
       "      <td>_, _, _, _, _, ARG1, _, V, _, ARG2, _, _, _, _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[This, BuzzMachine, post, argues, that, Google...</td>\n",
       "      <td>backfire</td>\n",
       "      <td>14</td>\n",
       "      <td>_, _, _, _, _, _, _, ARG1, _, _, ARGM-MOD, V, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[This, BuzzMachine, post, argues, that, Google...</td>\n",
       "      <td>'ve</td>\n",
       "      <td>15</td>\n",
       "      <td>_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence predicate  pred columns  \\\n",
       "0     [What, if, Google, Morphed, Into, GoogleOS, ?]   Morphed            11   \n",
       "1  [What, if, Google, expanded, on, its, search, ...  expanded            11   \n",
       "2  [(, And, ,, by, the, way, ,, is, anybody, else...       way            11   \n",
       "3  [(, And, ,, by, the, way, ,, is, anybody, else...        is            12   \n",
       "4  [(, And, ,, by, the, way, ,, is, anybody, else...       was            13   \n",
       "5  [This, BuzzMachine, post, argues, that, Google...      post            11   \n",
       "6  [This, BuzzMachine, post, argues, that, Google...    argues            12   \n",
       "7  [This, BuzzMachine, post, argues, that, Google...      rush            13   \n",
       "8  [This, BuzzMachine, post, argues, that, Google...  backfire            14   \n",
       "9  [This, BuzzMachine, post, argues, that, Google...       've            15   \n",
       "\n",
       "                                              labels  \n",
       "0                          _, _, ARG1, V, _, ARG2, _  \n",
       "1  _, _, ARG0, V, _, _, _, _, _, _, _, _, _, _, A...  \n",
       "2  _, _, _, _, _, V, _, _, _, _, _, _, _, _, _, _...  \n",
       "3  _, _, _, _, _, ARGM-DIS, _, V, ARG1, _, _, _, ...  \n",
       "4  _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _...  \n",
       "5  _, ARG2, V, _, _, _, _, _, _, _, _, _, _, _, _...  \n",
       "6  _, _, ARG0, V, _, _, _, _, _, _, _, ARG1, _, _...  \n",
       "7  _, _, _, _, _, ARG1, _, V, _, ARG2, _, _, _, _...  \n",
       "8  _, _, _, _, _, _, _, ARG1, _, _, ARGM-MOD, V, ...  \n",
       "9  _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `convert_to_dataset` function transforms data from pandas DataFrames (train, val, and test) into a DatasetDict. The function streamlines data preparation for machine learning tasks, facilitating easier management and processing of data.\n",
    "\n",
    "The labels_list contains all of the target labels used to train and test the model.\n",
    "\n",
    "The dataset variable now contains the transformed train, evaluation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = convert_to_dataset(df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', '_', 'C-V', 'ARGA', 'ARG4', 'ARG1', 'ARG0', 'ARG3', 'ARG2', 'ARG5', 'C-ARG0', 'C-ARG1', 'C-ARG4', 'R-ARG0', 'C-ARG2', 'R-ARG2', 'R-ARG3', 'R-ARG4', 'C-ARG3', 'R-ARG1', 'ARGM-MNR', 'ARGM-COM', 'ARGM-MOD', 'ARGM-DIS', 'ARGM-GOL', 'ARGM-LOC', 'ARGM-CXN', 'ARG1-DSP', 'ARGM-ADJ', 'ARGM-EXT', 'ARGM-REC', 'ARGM-NEG', 'ARGM-TMP', 'ARGM-PRP', 'ARGM-ADV', 'ARGM-PRR', 'ARGM-DIR', 'ARGM-LVB', 'ARGM-CAU', 'ARGM-PRD', 'C-ARGM-CXN', 'C-ARGM-DIR', 'C-ARGM-EXT', 'R-ARGM-GOL', 'C-ARGM-PRR', 'R-ARGM-LOC', 'R-ARGM-DIR', 'C-ARGM-COM', 'C-ARGM-LOC', 'C-ARGM-PRP', 'R-ARGM-COM', 'R-ARGM-ADV', 'R-ARGM-TMP', 'R-ARGM-MNR', 'C-ARG1-DSP', 'C-ARGM-MNR', 'C-ARGM-TMP', 'C-ARGM-GOL', 'R-ARGM-ADJ', 'C-ARGM-ADV', 'R-ARGM-CAU']\n"
     ]
    }
   ],
   "source": [
    "labels_list = get_labels_list_from_dataset(dataset)\n",
    "print(sorted(labels_list, key=lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Transformers Tokenizer is used to tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. The functions in the Tokenizer can be seen in bert.py, which is the code_ folder. \n",
    "\n",
    "By making use of the Tokenizer and target label list, the `tokenize_and_align_labels_pred` function preprocesses the data for a sequence labeling task by tokenizing sentences, aligning labels with tokens, and preparing them for model training or evaluation. \n",
    "\n",
    "More specifically, the function tokenizes sentences and predicates using the provided tokenizer, aligns the tokens from the sentence with the predicate tokens, iterates through each tokenized word in the sentence, checking if it matches any label and assigning the corresponding label index. If there's no match, it assigns the index of a placeholder label ('_') while if a predicate occurs multiple times in the sentence, the labels are repeated accordingly.\n",
    "\n",
    "It returns a list of lists, where each inner list represents the labels associated with each token in the sentence, including those corresponding to the predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9b10c19dea44649800be90e5481dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f0898470184815af4951138fac504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1fdf5cf0e64816b404e7ce1de9635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fef5fa6e2948739b42324b0bd63ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok = Tokenizer(model_checkpoint, labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the following output, the tokenized_datasets consists of the trainset, validation set, and the test set. The features that are in these datasets are: sentence, predicate, pred columns, labels, input_ids, and the attention mask\n",
    "\n",
    "The input_ids are the in the format: [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102, 2730, 102]. All tokens are tokenized and split into these word_ids. A [CLS] (input_id = 101) and [SEP] (input_id = 102) is added to these input_ids. We have made sure that the length of these input_ids, the labels and the attention_mask for each sentence are all the same, which is necessary for training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4364e582644c5286c2d3390a45577b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65841c88612c4c2898b803791f68d386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c181a66ee204d7d8e118eb97e04fb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'predicate', 'pred columns', 'labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 40498\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'predicate', 'pred columns', 'labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4979\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'predicate', 'pred columns', 'labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4802\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tok.tokenize_and_align_labels_pred, batched=True)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `dataset.map()` method, we apply the `tokenize_and_align_labels_pred` function to each part (train, dev and test) in the dataset in a parallel manner. \n",
    "\n",
    "The batched parameter set to True indicates that the function should be applied in batches, rather than one part at a time, to improve efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is used to save the tokenized trainfile, in order to check whether or not the training data has the correct format. When this augmented_train_tokenized.csv is opened, we can detect that the padding is added correctly, as well as the special tokens cls and sep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_data = []\n",
    "for sent in tokenized_datasets['train']:\n",
    "    tokens = tok.tokenizer.convert_ids_to_tokens(sent['input_ids'])\n",
    "    new_training_data.append(tokens)\n",
    "df_train_tokenized = pd.DataFrame(new_training_data)\n",
    "df_train_tokenized.to_csv('augmented_train_tokenized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have stored the weights for both baseline and advanced models at Google Drive, in the [folder](https://drive.google.com/drive/folders/1Vi92r9aPJ7laShdYxuFSEYCRyp7K54Qv?usp=sharing), or you can train them yourselves, it was about 5 minutes on colab's T4 GPU for 1 epoch. In this case you need to uncomment the cell with `trainer.train()` code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2d42add73f40ff84bb37d08c1e024f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# use this to train the model from scratch\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(labels_list))\n",
    "\n",
    "# or this to load the weights of finetuned model that you may download here:\n",
    "# model = AutoModelForTokenClassification.from_pretrained('model_checkpoints/baseline', num_labels=len(labels_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell gives us the arguments which are used to train the model. The model is saved in model_checkpoints/pred. Even though the metric 'seqeval' is given, this is not used to compute the evaluation of the model. The `data_collator` is used to handle the processing of the data into batches during traning. The `train_dataset` takes as input the whole `tokenized_datasets[\"train\"]`, and the evaluation dataset takes the entire `tokenized_datasets[\"validation\"]`. However, this dataset is not used here, since the evaluation itself is performed later in this notebook. The number of epochs is set to 1, which can eventually lead to underfitting, since the model might miss some patterns that have not been caught during this 1 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"model_checkpoints/baseline\",\n",
    "    evaluation_strategy = 'epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tok.tokenizer)\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tok.tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6330' max='6330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6330/6330 16:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.718018</td>\n",
       "      <td>0.620164</td>\n",
       "      <td>0.665513</td>\n",
       "      <td>0.959104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.742227</td>\n",
       "      <td>0.706682</td>\n",
       "      <td>0.724019</td>\n",
       "      <td>0.964691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.116274</td>\n",
       "      <td>0.730828</td>\n",
       "      <td>0.751348</td>\n",
       "      <td>0.740946</td>\n",
       "      <td>0.965687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.113452</td>\n",
       "      <td>0.754668</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.746802</td>\n",
       "      <td>0.967185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>0.750059</td>\n",
       "      <td>0.748300</td>\n",
       "      <td>0.749178</td>\n",
       "      <td>0.967234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6330, training_loss=0.12208793061604432, metrics={'train_runtime': 967.3278, 'train_samples_per_second': 209.329, 'train_steps_per_second': 6.544, 'total_flos': 4267297264010748.0, 'train_loss': 0.12208793061604432, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells predicts the validation set by using `trainer.predict`. \n",
    "These predictions are then saved into a bigger list (`list_predictions`), as well as the `true_labels`. The tokens with -100 are not used, since these indicate a special padding token (which are used to make all sentences the same length). For evaluation, these padding tokens must be removed.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "predictions_raw, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "\n",
    "predictions = np.argmax(predictions_raw, axis=2)\n",
    "\n",
    "list_predictions = [\n",
    "    [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_word_ids = []\n",
    "for sentence in dataset['test']['sentence']:\n",
    "    val_word_ids.append(tok.tokenizer(sentence, truncation=True, is_split_into_words=True).word_ids())\n",
    "\n",
    "df = pd.DataFrame(columns=['sentence', 'prediction', 'gold', 'word_ids'])\n",
    "for tokens, prediction, gold, word_ids in zip(tokenized_datasets['test']['input_ids'], list_predictions, true_labels, val_word_ids):\n",
    "    sentence = tok.tokenizer.decode(tokens)\n",
    "    df.loc[len(df.index)] = [sentence, prediction, gold, word_ids]\n",
    "# df.to_csv('data/output/base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_restored = []\n",
    "pred_restored = []\n",
    "for i, row in df.iterrows():\n",
    "    sentence = row[0]\n",
    "    orig_sentence = sentence.split('[SEP]')[0].split(' ')[1:]\n",
    "    prediction = row[1]\n",
    "    gold = row[2]\n",
    "    word_ids = row[3][1:-1]\n",
    "    gold_restored.append(shrink_predictions(word_ids, gold))\n",
    "    pred_restored.append(shrink_predictions(word_ids, prediction))\n",
    "\n",
    "df['gold_restored'] = gold_restored\n",
    "df['pred_restored'] = pred_restored\n",
    "df.to_csv('data/output/base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         'V'       0.98      0.97      0.97      3730\n",
      "         '_'       0.98      0.99      0.98     60225\n",
      "       'C-V'       0.83      0.71      0.77        14\n",
      "      'ARGA'       0.00      0.00      0.00         0\n",
      "      'ARG3'       0.00      0.00      0.00        49\n",
      "      'ARG2'       0.75      0.73      0.74       939\n",
      "      'ARG5'       0.00      0.00      0.00         1\n",
      "      'ARG0'       0.86      0.87      0.86      1412\n",
      "      'ARG4'       0.61      0.46      0.52        37\n",
      "      'ARG1'       0.84      0.87      0.86      2579\n",
      "    'C-ARG4'       0.00      0.00      0.00         0\n",
      "    'C-ARG2'       0.00      0.00      0.00         4\n",
      "    'R-ARG2'       0.00      0.00      0.00         2\n",
      "    'C-ARG0'       0.00      0.00      0.00         5\n",
      "    'R-ARG0'       0.82      0.93      0.87        40\n",
      "    'C-ARG1'       0.55      0.63      0.59        27\n",
      "    'C-ARG3'       0.00      0.00      0.00         4\n",
      "    'R-ARG3'       0.00      0.00      0.00         0\n",
      "    'R-ARG1'       0.86      0.66      0.75        47\n",
      "  'ARGM-EXT'       0.80      0.77      0.78        87\n",
      "  'ARGM-NEG'       0.93      0.93      0.93       284\n",
      "  'ARGM-DIS'       0.74      0.73      0.73       169\n",
      "  'ARGM-PRD'       0.33      0.08      0.13        38\n",
      "  'ARGM-PRP'       0.55      0.62      0.58        45\n",
      "  'ARGM-ADV'       0.69      0.64      0.66       356\n",
      "  'ARGM-GOL'       0.50      0.06      0.11        16\n",
      "  'ARGM-REC'       0.00      0.00      0.00         3\n",
      "  'ARG1-DSP'       0.00      0.00      0.00         0\n",
      "  'ARGM-MNR'       0.66      0.67      0.67       132\n",
      "  'ARGM-PRR'       0.70      0.72      0.71        53\n",
      "  'ARGM-DIR'       0.45      0.47      0.46        32\n",
      "  'ARGM-LVB'       0.84      0.89      0.86        54\n",
      "  'ARGM-TMP'       0.82      0.84      0.83       392\n",
      "  'ARGM-ADJ'       0.79      0.74      0.77       180\n",
      "  'ARGM-MOD'       0.93      0.95      0.94       281\n",
      "  'ARGM-COM'       0.00      0.00      0.00        10\n",
      "  'ARGM-LOC'       0.61      0.61      0.61       235\n",
      "  'ARGM-CAU'       0.70      0.64      0.67        47\n",
      "  'ARGM-CXN'       1.00      0.25      0.40         4\n",
      "'C-ARG1-DSP'       0.00      0.00      0.00         0\n",
      "'R-ARGM-DIR'       0.00      0.00      0.00         0\n",
      "'R-ARGM-LOC'       0.50      0.50      0.50         6\n",
      "'R-ARGM-ADV'       0.00      0.00      0.00         0\n",
      "'R-ARGM-MNR'       0.00      0.00      0.00         1\n",
      "'C-ARGM-EXT'       0.00      0.00      0.00         1\n",
      "'C-ARGM-LOC'       0.00      0.00      0.00         1\n",
      "'C-ARGM-CXN'       0.00      0.00      0.00         3\n",
      "'R-ARGM-ADJ'       0.00      0.00      0.00         0\n",
      "'R-ARGM-TMP'       0.00      0.00      0.00         6\n",
      "'R-ARGM-CAU'       0.00      0.00      0.00         1\n",
      "'C-ARGM-MNR'       0.00      0.00      0.00         0\n",
      "'R-ARGM-COM'       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     71552\n",
      "   macro avg       0.40      0.36      0.37     71552\n",
      "weighted avg       0.96      0.97      0.96     71552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from code_.evaluation import class_report_base\n",
    "class_report_base('data/output/base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the baseline model.\n",
    "The overall results of the baseline model evidently show its limitations also on the practical level. Although the model presents a high micro-averaged F1-score of 0.95, indicating that the model performs relatively well across all classes - when considering each prediction equally - this is quickly controverted by its very low macro average scores. Macro-average calculates the metric independently for each class and then takes the average across all classes, treating each class equally regardless of its size or frequency. A quick inspection of individual classes makes it clear that the high aggragated micro scores are mostly the product of the a few higly represented classes, including both the predicate class and the placeholder label. \n",
    "\n",
    "There is a considerable variation in precision, recall, and F1-score across labels as some classes have high precision and recall, while others have much lower scores including 0. The model seems to be performing well on frequent and well represented labels while the very infrequent ones do not get at all predicted. Classes like 'ARGM-NEG' (Negative Modifier) and 'ARGM-MOD' (Modal Modifier) have a big range in performance, with F1-scores ranging from 0.33 to 0.91, although they are not the most represented ones. On the other hand, 'ARG1' and 'ARG0' are more frequent and show promising but clearly lower results.\n",
    "\n",
    "While this approach provides a straightforward starting point, it presents notable limitations. One critical drawback is the model's inability to grasp contextual nuances, limiting its capacity to capture the intricate relationships between predicates and their arguments accurately. Due to the lack of contextual understanding, the model may struggle to disambiguate between different senses of predicates and may misclassify arguments. Moreover, relying on simplistic representations limits the model's generalization capabilities across diverse texts and domains, impacting its performance on unseen data. This can also be proven by the extremely low results on classes that are presented to the model in very low frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limitations of baseline Model. \n",
    "Giving only the predicate as a method to find the semantic roles for this task can resolve in finding the roles. When the context is given, this can help in detecting the semantic roles. When the focus is laid on the the surrounding words of the predicate, it is more likley that the model will be able to find Arg0 and Arg1 since they are typically right before and after the predicate.\n",
    "\n",
    "The obvious limitation is that the baseline model does not understand when 2 predicates are of the same token. In a sentence such as: My mom is a good cook and is lovely. having this same predicate 'is' could result in confusion for the different arguments per predicate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the advanced model we chose to implement a version of your baseline that represents the relation between predicate and sentence in a more sophisticated way which will hopefully manage to tackle the same predicate limitation entailed in the baseline.\n",
    "\n",
    "More specifically, instead of only representing the predicate with its corresponding token, we tried to distinguish it even further by employing its context: \n",
    "\n",
    "[CLS] Barack Obama went to Paris [SEP] Obama,went,to [SEP].\n",
    "\n",
    "The previous and next tokens - together with the predicate itself - are used to represent the predicate and differentiate using context. Preprocessing the files for this advanced model is done by using advanced_process_file in process_conll.py\n",
    "\n",
    "Most code cells are the same as the baseline model. Only the input of this model has been changed to the input that is described previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_process_file(): dataframe len: 4979\n",
      "advanced_process_file(): dataframe len: 40498\n",
      "advanced_process_file(): dataframe len: 4802\n"
     ]
    }
   ],
   "source": [
    "df_val = advanced_process_file('data/raw/en_ewt-up-dev.conllu')\n",
    "df_train = advanced_process_file('data/raw/en_ewt-up-train.conllu')\n",
    "df_test = advanced_process_file('data/raw/en_ewt-up-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = convert_to_dataset(df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By again making use of the `Tokenizer` and target label list, the `tokenize_and_align_labels_context` function preprocesses the data for a sequence labeling task by tokenizing sentences, aligning labels with tokens, and preparing them for model training or evaluation. \n",
    "\n",
    "More specifically, the function tokenizes sentences and predicates using the provided tokenizer, aligns the tokens from the sentence with the predicate tokens, iterates through each tokenized word in the sentence, checking if it matches any label and assigning the corresponding label index. If there's no match, it assigns the index of a placeholder label ('_') while if a predicate occurs multiple times in the sentence, the labels are repeated accordingly.\n",
    "\n",
    "It returns a list of lists, where each inner list represents the labels associated with each token in the sentence, including those corresponding to the predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ad0b5a1df54cfb84b76d1be6c73e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c5130a910c47198de62589383f70e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328deac150d487ca03fd72f3a86d834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tok.tokenize_and_align_labels_context, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(labels_list))\n",
    "# model = AutoModelForTokenClassification.from_pretrained('model_checkpoints/advanced', num_labels=len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"model_checkpoints/context\",\n",
    "    evaluation_strategy = 'epoch',\n",
    "    learning_rate=2e-5,\n",
    "    save_steps=7000,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tok.tokenizer)\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tok.tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102, 2749, 2730, 21146, 28209, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6330' max='6330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6330/6330 16:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.154411</td>\n",
       "      <td>0.737996</td>\n",
       "      <td>0.722282</td>\n",
       "      <td>0.730054</td>\n",
       "      <td>0.958688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.128525</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>0.765938</td>\n",
       "      <td>0.774131</td>\n",
       "      <td>0.965106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.124424</td>\n",
       "      <td>0.774987</td>\n",
       "      <td>0.794373</td>\n",
       "      <td>0.784560</td>\n",
       "      <td>0.966382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.121372</td>\n",
       "      <td>0.792312</td>\n",
       "      <td>0.796682</td>\n",
       "      <td>0.794491</td>\n",
       "      <td>0.968110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.122214</td>\n",
       "      <td>0.790638</td>\n",
       "      <td>0.802369</td>\n",
       "      <td>0.796460</td>\n",
       "      <td>0.968329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6330, training_loss=0.12249502872027115, metrics={'train_runtime': 986.8706, 'train_samples_per_second': 205.184, 'train_steps_per_second': 6.414, 'total_flos': 4382057446823628.0, 'train_loss': 0.12249502872027115, 'epoch': 5.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_raw, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "predictions = np.argmax(predictions_raw, axis=2)\n",
    "\n",
    "list_predictions = [\n",
    "    [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=list_predictions, references=true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_word_ids = []\n",
    "for sentence in dataset['test']['sentence']:\n",
    "    val_word_ids.append(tok.tokenizer(sentence, truncation=True, is_split_into_words=True).word_ids())\n",
    "\n",
    "df = pd.DataFrame(columns=['sentence', 'prediction', 'gold', 'word_ids'])\n",
    "for tokens, prediction, gold, word_ids in zip(tokenized_datasets['test']['input_ids'], list_predictions, true_labels, val_word_ids):\n",
    "    sentence = tok.tokenizer.decode(tokens)\n",
    "    df.loc[len(df.index)] = [sentence, prediction, gold, word_ids]\n",
    "\n",
    "gold_restored = []\n",
    "pred_restored = []\n",
    "for i, row in df.iterrows():\n",
    "    sentence = row[0]\n",
    "    orig_sentence = sentence.split('[SEP]')[0].split(' ')[1:]\n",
    "    prediction = row[1]\n",
    "    gold = row[2]\n",
    "    word_ids = row[3][1:-1]\n",
    "    gold_restored.append(shrink_predictions(word_ids, gold))\n",
    "    pred_restored.append(shrink_predictions(word_ids, prediction))\n",
    "\n",
    "df['gold_restored'] = gold_restored\n",
    "df['pred_restored'] = pred_restored\n",
    "df.to_csv('data/output/advanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         'V'       0.99      1.00      1.00      5885\n",
      "         '_'       0.99      0.99      0.99     60852\n",
      "       'C-V'       0.77      0.71      0.74        14\n",
      "      'ARGA'       0.00      0.00      0.00         0\n",
      "      'ARG3'       0.50      0.02      0.04        50\n",
      "      'ARG2'       0.79      0.79      0.79      1101\n",
      "      'ARG5'       0.00      0.00      0.00         1\n",
      "      'ARG0'       0.85      0.88      0.87      1686\n",
      "      'ARG4'       0.65      0.59      0.62        41\n",
      "      'ARG1'       0.86      0.88      0.87      3102\n",
      "    'C-ARG4'       0.00      0.00      0.00         0\n",
      "    'C-ARG2'       1.00      0.20      0.33         5\n",
      "    'R-ARG2'       0.00      0.00      0.00         2\n",
      "    'C-ARG0'       0.00      0.00      0.00         5\n",
      "    'R-ARG0'       0.86      0.93      0.89        54\n",
      "    'C-ARG1'       0.46      0.60      0.52        30\n",
      "    'C-ARG3'       0.00      0.00      0.00         7\n",
      "    'R-ARG3'       0.00      0.00      0.00         0\n",
      "    'R-ARG1'       0.81      0.75      0.78        52\n",
      "  'ARGM-EXT'       0.82      0.83      0.82       138\n",
      "  'ARGM-NEG'       0.95      0.95      0.95       404\n",
      "  'ARGM-DIS'       0.74      0.75      0.75       200\n",
      "  'ARGM-PRD'       0.55      0.22      0.31        50\n",
      "  'ARGM-PRP'       0.44      0.60      0.51        45\n",
      "  'ARGM-ADV'       0.72      0.69      0.70       409\n",
      "  'ARGM-GOL'       0.00      0.00      0.00        16\n",
      "  'ARGM-REC'       0.00      0.00      0.00         7\n",
      "  'ARG1-DSP'       0.00      0.00      0.00         0\n",
      "  'ARGM-MNR'       0.61      0.68      0.64       155\n",
      "  'ARGM-PRR'       0.70      0.76      0.73        63\n",
      "  'ARGM-DIR'       0.54      0.55      0.54        40\n",
      "  'ARGM-LVB'       0.86      0.88      0.87        65\n",
      "  'ARGM-TMP'       0.82      0.87      0.85       445\n",
      "  'ARGM-ADJ'       0.85      0.84      0.84       263\n",
      "  'ARGM-MOD'       0.98      0.98      0.98       373\n",
      "  'ARGM-COM'       0.33      0.10      0.15        10\n",
      "  'ARGM-LOC'       0.63      0.64      0.63       246\n",
      "  'ARGM-CAU'       0.66      0.55      0.60        49\n",
      "  'ARGM-CXN'       0.80      0.57      0.67         7\n",
      "'C-ARG1-DSP'       0.00      0.00      0.00         0\n",
      "'R-ARGM-DIR'       0.00      0.00      0.00         0\n",
      "'R-ARGM-LOC'       0.50      0.50      0.50         6\n",
      "'R-ARGM-ADV'       0.00      0.00      0.00         0\n",
      "'R-ARGM-MNR'       0.00      0.00      0.00         1\n",
      "'C-ARGM-EXT'       0.00      0.00      0.00         1\n",
      "'C-ARGM-LOC'       0.00      0.00      0.00         1\n",
      "'C-ARGM-CXN'       1.00      0.33      0.50         3\n",
      "'R-ARGM-ADJ'       0.00      0.00      0.00         0\n",
      "'R-ARGM-TMP'       0.00      0.00      0.00         6\n",
      "'R-ARGM-CAU'       0.00      0.00      0.00         1\n",
      "'C-ARGM-MNR'       0.00      0.00      0.00         0\n",
      "'R-ARGM-COM'       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     75891\n",
      "   macro avg       0.44      0.40      0.40     75891\n",
      "weighted avg       0.97      0.97      0.97     75891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from code_.evaluation import class_report_advanced\n",
    "class_report_base('data/output/advanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         'V'       0.99      1.00      1.00      5885\n",
      "         '_'       0.99      0.99      0.99     60852\n",
      "       'C-V'       0.77      0.71      0.74        14\n",
      "      'ARGA'       0.00      0.00      0.00         0\n",
      "      'ARG3'       0.50      0.02      0.04        50\n",
      "      'ARG2'       0.79      0.79      0.79      1101\n",
      "      'ARG5'       0.00      0.00      0.00         1\n",
      "      'ARG0'       0.85      0.88      0.87      1686\n",
      "      'ARG4'       0.65      0.59      0.62        41\n",
      "      'ARG1'       0.86      0.88      0.87      3102\n",
      "    'C-ARG4'       0.00      0.00      0.00         0\n",
      "    'C-ARG2'       1.00      0.20      0.33         5\n",
      "    'R-ARG2'       0.00      0.00      0.00         2\n",
      "    'C-ARG0'       0.00      0.00      0.00         5\n",
      "    'R-ARG0'       0.86      0.93      0.89        54\n",
      "    'C-ARG1'       0.46      0.60      0.52        30\n",
      "    'C-ARG3'       0.00      0.00      0.00         7\n",
      "    'R-ARG3'       0.00      0.00      0.00         0\n",
      "    'R-ARG1'       0.81      0.75      0.78        52\n",
      "  'ARGM-EXT'       0.82      0.83      0.82       138\n",
      "  'ARGM-NEG'       0.95      0.95      0.95       404\n",
      "  'ARGM-DIS'       0.74      0.75      0.75       200\n",
      "  'ARGM-PRD'       0.55      0.22      0.31        50\n",
      "  'ARGM-PRP'       0.44      0.60      0.51        45\n",
      "  'ARGM-ADV'       0.72      0.69      0.70       409\n",
      "  'ARGM-GOL'       0.00      0.00      0.00        16\n",
      "  'ARGM-REC'       0.00      0.00      0.00         7\n",
      "  'ARG1-DSP'       0.00      0.00      0.00         0\n",
      "  'ARGM-MNR'       0.61      0.68      0.64       155\n",
      "  'ARGM-PRR'       0.70      0.76      0.73        63\n",
      "  'ARGM-DIR'       0.54      0.55      0.54        40\n",
      "  'ARGM-LVB'       0.86      0.88      0.87        65\n",
      "  'ARGM-TMP'       0.82      0.87      0.85       445\n",
      "  'ARGM-ADJ'       0.85      0.84      0.84       263\n",
      "  'ARGM-MOD'       0.98      0.98      0.98       373\n",
      "  'ARGM-COM'       0.33      0.10      0.15        10\n",
      "  'ARGM-LOC'       0.63      0.64      0.63       246\n",
      "  'ARGM-CAU'       0.66      0.55      0.60        49\n",
      "  'ARGM-CXN'       0.80      0.57      0.67         7\n",
      "'C-ARG1-DSP'       0.00      0.00      0.00         0\n",
      "'R-ARGM-DIR'       0.00      0.00      0.00         0\n",
      "'R-ARGM-LOC'       0.50      0.50      0.50         6\n",
      "'R-ARGM-ADV'       0.00      0.00      0.00         0\n",
      "'R-ARGM-MNR'       0.00      0.00      0.00         1\n",
      "'C-ARGM-EXT'       0.00      0.00      0.00         1\n",
      "'C-ARGM-LOC'       0.00      0.00      0.00         1\n",
      "'C-ARGM-CXN'       1.00      0.33      0.50         3\n",
      "'R-ARGM-ADJ'       0.00      0.00      0.00         0\n",
      "'R-ARGM-TMP'       0.00      0.00      0.00         6\n",
      "'R-ARGM-CAU'       0.00      0.00      0.00         1\n",
      "'C-ARGM-MNR'       0.00      0.00      0.00         0\n",
      "'R-ARGM-COM'       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     75891\n",
      "   macro avg       0.44      0.40      0.40     75891\n",
      "weighted avg       0.97      0.97      0.97     75891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from code_.evaluation import class_report_advanced\n",
    "class_report_base('data/output/advanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output exceeds the size limit. Open the full output data in a text editor\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         'V'       1.00      1.00      1.00       221\n",
    "         '_'       0.96      0.97      0.96      3727\n",
    "       'C-V'       0.00      0.00      0.00         0\n",
    "      'ARGA'       0.00      0.00      0.00         0\n",
    "      'ARG3'       0.00      0.00      0.00         2\n",
    "      'ARG2'       1.00      0.11      0.20        18\n",
    "      'ARG5'       0.00      0.00      0.00         0\n",
    "      'ARG0'       0.82      0.89      0.85       420\n",
    "      'ARG4'       0.00      0.00      0.00         0\n",
    "      'ARG1'       0.82      0.84      0.83       337\n",
    "    'C-ARG4'       0.00      0.00      0.00         0\n",
    "    'C-ARG2'       0.00      0.00      0.00         0\n",
    "    'R-ARG2'       0.00      0.00      0.00         0\n",
    "    'C-ARG0'       0.00      0.00      0.00         0\n",
    "    'R-ARG0'       0.00      0.00      0.00         0\n",
    "    'C-ARG1'       0.00      0.00      0.00         0\n",
    "    'C-ARG3'       0.00      0.00      0.00         0\n",
    "    'R-ARG3'       0.00      0.00      0.00         0\n",
    "    'R-ARG1'       0.00      0.00      0.00         0\n",
    "  'ARGM-EXT'       0.60      0.60      0.60         5\n",
    "  'ARGM-NEG'       0.50      1.00      0.67         4\n",
    "  'ARGM-DIS'       0.74      0.60      0.67        91\n",
    "  'ARGM-PRD'       0.00      0.00      0.00         2\n",
    "...\n",
    "   micro avg       0.93      0.93      0.93      4979\n",
    "   macro avg       0.20      0.18      0.17      4979\n",
    "weighted avg       0.93      0.93      0.93      4979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Results of Advanced Model\n",
    "The advanced model has a macro average of 0.23 for precision, which means that when each class is treated equally, this value gives the model's overall performance of precision. This macro average is 0.21 for recall, and 0.21 for f1. All of these values are lower then the macro averages of the baseline model. \n",
    "\n",
    "The micro average is the same as the baseline model, which means that when the classes are given the same weight, the model the precision, recall and f1-score all have a value of 0.95\n",
    "\n",
    "The most common arguments in the dataset, and most common arguments in SRL are Arg0 and Arg1. Arg0 has a high precision, recall and f1-score (0.78, 0.82, 0.80), same for Arg1 (0.72, 0.81, 0.77). There are many instances that the model is trained on which have these Arg0 and Arg1 arguments in the sentence. Therefore, it was expected that these values would be higher then other argument-values. \n",
    "\n",
    "Arg2 represents the instrument used in SRL. This is also a very important argument that needs to be loooked into. The precision, recall and f1-score for this ARG2 are: (0.63, 0.58, 0.60). \n",
    "\n",
    "For example in this sentence: From the ap comes this story : [SEP] ap comes this [SEP], the model predicts 'AP' as Arg0 when in fact, the gold states this as 'Arg2'. But in the sentence: [CLS] it seems clear to me that the manhunt for high baath officials in the sunni heartland is being done wrong, or at least in ways that are bad for us standing with local iraqis. and 'seems' is the predicate, the model predicts that 'clear' and 'me' are both ARG2. However, gold labels say that 'clear' is ARG1 and 'me' is ARG2. \n",
    "\n",
    "However, when the predicate is 'clear', the model predicts that 'me' is ARG2, when it is in fact not an argument (as can be seen in the gold data). When the predicate is 'bad', ARG2 is 'standing'. But again the model predicts that there are 2 ARG2's, which are 'US' and 'standing'\n",
    "\n",
    "In the sentence: this operation would only consolidate the terrorist acts in the world and would not bring peace to the region, \"\" the message claimed., where 'bring' is the predicate, the model correctly labels 'region' as ARG2. This could explain that the model learns when a 'to' is presented after the predicate, the following token (but excluding 'the'), is labeled as ARG2. Here, it seems as if the model also learns that only the headword can be labeled as an argument, not 'the'.  \n",
    "\n",
    "The sentence: it's not quite as freewheeling an environment as you'd imagine : sergey brin has actually created a mathematical'proof'that the company's self - driven research strategy, which gives employees one day a week to do research projects on their own, is a good, respectable idea. The predicate is \"'s\". The first few tokens are labeled correctly (It, ', s, not) = ['ARG1', 'V', 'V', 'ARGM-NEG']. The next token 'quite' is then labeled as ARG2, as well as 'freewheeling', 'an', and 'environment'. Again, thre are multiple ARG2's predicted in the sentence when in fact the correct ARG2 is 'you'. This is interesting, since the model might be trained on sentences with this 'as ... as' structure, and learned that when an 'as' is presented, the following token should be an ARG2 (which is the case for 'you'). However, it could be that it detects the first 'as' and directly labels the next token as ARG2, not looking further into the sentence as well as the token 'as' itself. Moreover, here, it does not detect the headword of a constituent, which is a good indication of which token needs to be labeled, and which one does not. This could also be further implemented in future work.\n",
    "\n",
    "In the sentence: the food is mediocre at best. --> the predicate is 'is' and the sentence consists of 3 ARG2's. The model predicts these 3 ARG2's correctly. However, the gold gives ARGM-ADV to 'best', the model does not detect this. \n",
    "\n",
    "When we look at ARG1, we see that many times, this ARG1 is right before the predicate and is correctly labeled. In the sentence: 4826: and they seem to be posted at fairly regular intervals? The ARG1 in this sentence is correctly labeled to be 'they'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the models\n",
    "The overall results of the baseline model evidently show its limitations also on the practical level. Although the model presents a high micro-averaged F1-score of 0.95, indicating that the model performs relatively well across all classes - when considering each prediction equally - this is quickly controverted by its very low macro average scores. Macro-average calculates the metric independently for each class and then takes the average across all classes, treating each class equally regardless of its size or frequency. A quick inspection of individual classes makes it clear that the high aggragated micro scores are mostly the product of the a few higly represented classes, including both the predicate class and the placeholder label. \n",
    "\n",
    "There is a considerable variation in precision, recall, and F1-score across labels as some classes have high precision and recall, while others have much lower scores including 0. The model seems to be performing well on frequent and well represented labels while the very infrequent ones do not get at all predicted. Classes like 'ARGM-NEG' (Negative Modifier) and 'ARGM-MOD' (Modal Modifier) have a big range in performance, with F1-scores ranging from 0.33 to 0.91, although they are not the most represented ones. On the other hand, 'ARG1' and 'ARG0' are more frequent and show promising but clearly lower results.\n",
    "\n",
    "While this approach provides a straightforward starting point, it presents notable limitations. One critical drawback is the model's inability to grasp contextual nuances, limiting its capacity to capture the intricate relationships between predicates and their arguments accurately. Due to the lack of contextual understanding, the model may struggle to disambiguate between different senses of predicates and may misclassify arguments. Moreover, relying on simplistic representations limits the model's generalization capabilities across diverse texts and domains, impacting its performance on unseen data. This can also be proven by the extremely low results on classes that are presented to the model in very low frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity in performance between the baseline and advanced models suggests that the baseline approach of representing predicates solely by themselves can be surprisingly effective for well represented and common argument labels. This indicates that for certain datasets, simple representations may suffice to capture the necessary information for Semantic Role Labeling (SRL). However, the overall experiment underscores the importance of predicate representation in SRL tasks. While more advanced representations may offer additional contextual information, they do not always guarantee significant improvements over simpler approaches. The fact that the advanced model did not outperform the baseline model indicates that the additional contextual information provided by the previous and following tokens may not be as influential or as sufficient as thought.\n",
    "\n",
    "\n",
    "Nevertheless, the difference in performance among some classes - as discussed above - between the two models presents extreme interest and should be further explored. What is more,  future work could explore incorporating broader contextual cues, such as expanding on the previous and next tokens representations with including more tokens. In addition to contextual information, exploring the role of syntactic structures, such as dependency parsing or constituency parsing, in predicate representation could offer valuable insights into improving SRL model performance. For example,  detecting the headword of a constituent, could be a good indication of which token needs to be labeled, and which one does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models in: \n",
    "https://drive.google.com/drive/folders/1Vi92r9aPJ7laShdYxuFSEYCRyp7K54Qv?usp=share_link "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "21634ba1c762bc3505d86a0c5bab9f12f9ed8aa21c75b1f37c314fb51f344c98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
